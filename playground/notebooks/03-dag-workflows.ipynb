{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAG Workflow Execution\n",
    "\n",
    "Execute multi-step workflows with dependencies using the DAG (Directed Acyclic Graph) executor.\n",
    "\n",
    "**Features:**\n",
    "- Parallel execution of independent tasks\n",
    "- Dependency management between tasks\n",
    "- State management and checkpoints\n",
    "- Event streaming for real-time progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import {\n",
    "  DenoSandboxExecutor,\n",
    "  ParallelExecutor,\n",
    "  createInitialState,\n",
    "  type DAGExecutionResult,\n",
    "  type ToolExecutor\n",
    "} from \"jsr:@casys/mcp-gateway\";\n",
    "\n",
    "// Create sandbox for code execution\n",
    "const sandbox = new DenoSandboxExecutor({\n",
    "  timeout: 5000,\n",
    "  memoryLimit: 128,\n",
    "});\n",
    "\n",
    "console.log(\"‚úÖ DAG executor ready\");"
   ]
  },
  {
   "cell_type": "code",
   "source": "// Import visualization helpers\nimport { dagToMermaid, layersToMermaid, dagStats } from \"../lib/viz.ts\";\n\nconsole.log(\"üìä Visualization helpers loaded\");",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Simple DAG\n\nCreate a workflow with 3 tasks:\n```\nfetchData ‚Üí processData ‚Üí aggregate\n```"
   ]
  },
  {
   "cell_type": "code",
   "source": "// Convert DAG to proper format\nconst dagWorkflow = {\n  id: \"simple-dag\",\n  tasks: [\n    { id: \"fetchData\", tool_name: \"sandbox\", dependencies: [] },\n    { id: \"processData\", tool_name: \"sandbox\", dependencies: [\"fetchData\"] },\n    { id: \"aggregate\", tool_name: \"sandbox\", dependencies: [\"processData\"] }\n  ]\n};\n\nconsole.log(dagToMermaid(dagWorkflow));\nconsole.log(\"\\n\" + dagStats(dagWorkflow));",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Visualize DAG Structure\n\nView the DAG as a Mermaid diagram:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const dag = {\n",
    "  tasks: {\n",
    "    fetchData: {\n",
    "      tool: \"sandbox\",\n",
    "      params: { code: \"return { numbers: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] }\" },\n",
    "      dependencies: []\n",
    "    },\n",
    "    processData: {\n",
    "      tool: \"sandbox\",\n",
    "      params: { code: \"return context.numbers.map(n => n * n)\" },\n",
    "      dependencies: [\"fetchData\"]\n",
    "    },\n",
    "    aggregate: {\n",
    "      tool: \"sandbox\",\n",
    "      params: { code: \"return { sum: context.reduce((a, b) => a + b, 0), count: context.length }\" },\n",
    "      dependencies: [\"processData\"]\n",
    "    }\n",
    "  }\n",
    "};\n",
    "\n",
    "console.log(\"üìä DAG defined:\");\n",
    "console.log(\"   Tasks:\", Object.keys(dag.tasks).join(\" ‚Üí \"));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute DAG Manually\n\nStep through each task to see how it works:"
   ]
  },
  {
   "cell_type": "code",
   "source": "const parallelDagWorkflow = {\n  id: \"parallel-dag\",\n  tasks: [\n    { id: \"taskA\", tool_name: \"random\", dependencies: [] },\n    { id: \"taskB\", tool_name: \"random\", dependencies: [] },\n    { id: \"combine\", tool_name: \"merge\", dependencies: [\"taskA\", \"taskB\"] }\n  ]\n};\n\n// Show as layers (parallel execution groups)\nconst layers = [\n  [parallelDagWorkflow.tasks[0], parallelDagWorkflow.tasks[1]], // Layer 0: parallel\n  [parallelDagWorkflow.tasks[2]] // Layer 1: fan-in\n];\n\nconsole.log(layersToMermaid(layers));\nconsole.log(\"\\nüí° Layer 0 executes in parallel, Layer 1 waits for both\");",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Visualize Parallel Execution\n\nSee parallel tasks and fan-in pattern:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Execute fetchData\n",
    "console.log(\"\\nüì• Step 1: fetchData\");\n",
    "const result1 = await sandbox.execute(dag.tasks.fetchData.params.code);\n",
    "console.log(\"   Result:\", result1.result);\n",
    "\n",
    "// Execute processData with context from fetchData\n",
    "console.log(\"\\n‚öôÔ∏è  Step 2: processData\");\n",
    "const result2 = await sandbox.execute(\n",
    "  dag.tasks.processData.params.code,\n",
    "  result1.result // Pass previous result as context\n",
    ");\n",
    "console.log(\"   Result:\", result2.result);\n",
    "\n",
    "// Execute aggregate with context from processData\n",
    "console.log(\"\\nüìä Step 3: aggregate\");\n",
    "const result3 = await sandbox.execute(\n",
    "  dag.tasks.aggregate.params.code,\n",
    "  result2.result\n",
    ");\n",
    "console.log(\"   Result:\", result3.result);\n",
    "\n",
    "console.log(\"\\n‚úÖ Workflow complete!\");"
   ]
  },
  {
   "cell_type": "code",
   "source": "const complexDagWorkflow = {\n  id: \"complex-dag\",\n  tasks: [\n    { id: \"fetch\", tool_name: \"fetch\", dependencies: [] },\n    { id: \"extract\", tool_name: \"extract\", dependencies: [\"fetch\"] },\n    { id: \"validate\", tool_name: \"validate\", dependencies: [\"fetch\"] },\n    { id: \"enrich\", tool_name: \"enrich\", dependencies: [\"fetch\"] },\n    { id: \"transform\", tool_name: \"transform\", dependencies: [\"extract\", \"validate\", \"enrich\"] },\n    { id: \"save\", tool_name: \"save\", dependencies: [\"transform\"] }\n  ]\n};\n\nconst complexLayers = [\n  [complexDagWorkflow.tasks[0]], // Layer 0: fetch\n  [complexDagWorkflow.tasks[1], complexDagWorkflow.tasks[2], complexDagWorkflow.tasks[3]], // Layer 1: parallel\n  [complexDagWorkflow.tasks[4]], // Layer 2: transform (fan-in)\n  [complexDagWorkflow.tasks[5]]  // Layer 3: save\n];\n\nconsole.log(layersToMermaid(complexLayers));\nconsole.log(\"\\nüìä 4 layers: fetch ‚Üí parallel processing ‚Üí transform ‚Üí save\");",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Visualize Complex Multi-Layer DAG\n\nFan-out ‚Üí Parallel Processing ‚Üí Fan-in pattern:",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel DAG Execution\n\nNow with tasks that can run in parallel:\n```\n    ‚îå‚îÄ taskA ‚îÄ‚îê\nstart‚îÇ         ‚îÇ‚Üí combine\n    ‚îî‚îÄ taskB ‚îÄ‚îò\n```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const parallelDag = {\n",
    "  tasks: {\n",
    "    taskA: {\n",
    "      tool: \"sandbox\",\n",
    "      params: { code: \"return { source: 'A', value: Math.random() * 100 }\" },\n",
    "      dependencies: []\n",
    "    },\n",
    "    taskB: {\n",
    "      tool: \"sandbox\",\n",
    "      params: { code: \"return { source: 'B', value: Math.random() * 100 }\" },\n",
    "      dependencies: []\n",
    "    },\n",
    "    combine: {\n",
    "      tool: \"sandbox\",\n",
    "      params: { code: \"return { total: context.A.value + context.B.value, sources: [context.A.source, context.B.source] }\" },\n",
    "      dependencies: [\"taskA\", \"taskB\"]\n",
    "    }\n",
    "  }\n",
    "};\n",
    "\n",
    "console.log(\"üîÄ Parallel DAG:\");\n",
    "console.log(\"   taskA (no deps)\");\n",
    "console.log(\"   taskB (no deps)\");\n",
    "console.log(\"   combine (depends on A and B)\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Execute A and B in parallel\n",
    "console.log(\"\\n‚ö° Executing taskA and taskB in parallel...\");\n",
    "\n",
    "const [resultA, resultB] = await Promise.all([\n",
    "  sandbox.execute(parallelDag.tasks.taskA.params.code),\n",
    "  sandbox.execute(parallelDag.tasks.taskB.params.code)\n",
    "]);\n",
    "\n",
    "console.log(\"   taskA:\", resultA.result);\n",
    "console.log(\"   taskB:\", resultB.result);\n",
    "\n",
    "// Combine results\n",
    "console.log(\"\\nüîó Combining results...\");\n",
    "const combined = await sandbox.execute(\n",
    "  parallelDag.tasks.combine.params.code,\n",
    "  { A: resultA.result, B: resultB.result }\n",
    ");\n",
    "\n",
    "console.log(\"   Combined:\", combined.result);\n",
    "console.log(\"\\n‚úÖ Parallel workflow complete!\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complex DAG with Multiple Layers\n\n```\n       ‚îå‚îÄ extract ‚îÄ‚îê\nfetch ‚îÄ‚îº‚îÄ validate ‚îÄ‚îº‚îÄ transform ‚îÄ save\n       ‚îî‚îÄ enrich ‚îÄ‚îÄ‚îò\n```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const complexDag = {\n",
    "  tasks: {\n",
    "    fetch: {\n",
    "      code: \"return { users: [{id: 1, name: 'Alice'}, {id: 2, name: 'Bob'}] }\",\n",
    "      deps: []\n",
    "    },\n",
    "    extract: {\n",
    "      code: \"return context.users.map(u => u.name)\",\n",
    "      deps: [\"fetch\"]\n",
    "    },\n",
    "    validate: {\n",
    "      code: \"return { valid: context.users.every(u => u.id && u.name), count: context.users.length }\",\n",
    "      deps: [\"fetch\"]\n",
    "    },\n",
    "    enrich: {\n",
    "      code: \"return context.users.map(u => ({ ...u, createdAt: new Date().toISOString() }))\",\n",
    "      deps: [\"fetch\"]\n",
    "    },\n",
    "    transform: {\n",
    "      code: \"return { names: context.extract, isValid: context.validate.valid, enriched: context.enrich }\",\n",
    "      deps: [\"extract\", \"validate\", \"enrich\"]\n",
    "    },\n",
    "    save: {\n",
    "      code: \"return { saved: true, summary: `Saved ${context.names.length} users, valid: ${context.isValid}` }\",\n",
    "      deps: [\"transform\"]\n",
    "    }\n",
    "  }\n",
    "};\n",
    "\n",
    "// Execute layer by layer\n",
    "const results: Record<string, unknown> = {};\n",
    "\n",
    "console.log(\"üèóÔ∏è  Executing complex DAG...\\n\");\n",
    "\n",
    "// Layer 1: fetch\n",
    "console.log(\"Layer 1: fetch\");\n",
    "results.fetch = (await sandbox.execute(complexDag.tasks.fetch.code)).result;\n",
    "console.log(\"   ‚úì fetch complete\");\n",
    "\n",
    "// Layer 2: extract, validate, enrich (parallel)\n",
    "console.log(\"\\nLayer 2: extract, validate, enrich (parallel)\");\n",
    "const [extract, validate, enrich] = await Promise.all([\n",
    "  sandbox.execute(complexDag.tasks.extract.code, results.fetch),\n",
    "  sandbox.execute(complexDag.tasks.validate.code, results.fetch),\n",
    "  sandbox.execute(complexDag.tasks.enrich.code, results.fetch)\n",
    "]);\n",
    "results.extract = extract.result;\n",
    "results.validate = validate.result;\n",
    "results.enrich = enrich.result;\n",
    "console.log(\"   ‚úì extract, validate, enrich complete\");\n",
    "\n",
    "// Layer 3: transform\n",
    "console.log(\"\\nLayer 3: transform\");\n",
    "results.transform = (await sandbox.execute(\n",
    "  complexDag.tasks.transform.code,\n",
    "  { extract: results.extract, validate: results.validate, enrich: results.enrich }\n",
    ")).result;\n",
    "console.log(\"   ‚úì transform complete\");\n",
    "\n",
    "// Layer 4: save\n",
    "console.log(\"\\nLayer 4: save\");\n",
    "results.save = (await sandbox.execute(\n",
    "  complexDag.tasks.save.code,\n",
    "  results.transform\n",
    ")).result;\n",
    "console.log(\"   ‚úì save complete\");\n",
    "\n",
    "console.log(\"\\nüìä Final result:\");\n",
    "console.log(JSON.stringify(results.save, null, 2));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**DAG Workflows enable:**\n",
    "- ‚úÖ Sequential task execution with dependencies\n",
    "- ‚úÖ Parallel execution of independent tasks\n",
    "- ‚úÖ Context passing between tasks\n",
    "- ‚úÖ Complex multi-layer workflows\n",
    "\n",
    "**Use cases:**\n",
    "- ETL pipelines\n",
    "- Data processing workflows\n",
    "- Multi-step AI agent tasks\n",
    "- Orchestrated tool execution"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}